{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17083bf5",
   "metadata": {},
   "source": [
    "# Erosion Detection Training\n",
    "\n",
    "This notebook downloads a sample dataset, adds synthetic sensor data, computes correlations between image features and sensors, and trains a simple model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c15a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies if running on a fresh environment\n",
    "!pip install -q -r ../requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718c5e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7386eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download CIFAR10 as a placeholder dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = datasets.CIFAR10(root='data', train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create synthetic sensor data correlated with class label\n",
    "np.random.seed(0)\n",
    "labels = np.array(train_ds.targets)\n",
    "sensors = pd.DataFrame({\n",
    "    'rainfall': labels * 10 + np.random.randn(len(labels)) * 2,\n",
    "    'slope': labels * 5 + np.random.randn(len(labels)) * 1.5,\n",
    "    'humidity': labels * 8 + np.random.randn(len(labels)) * 1.0,\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8529850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlate sensors with labels\n",
    "correlation = sensors.corrwith(pd.Series(labels, name='label'))\n",
    "print(correlation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e62971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset that includes images and sensors\n",
    "class SensorImageDataset(Dataset):\n",
    "    def __init__(self, image_ds, sensor_df):\n",
    "        self.image_ds = image_ds\n",
    "        self.sensor_df = sensor_df.reset_index(drop=True)\n",
    "    def __len__(self):\n",
    "        return len(self.image_ds)\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.image_ds[idx]\n",
    "        sensors = torch.tensor(self.sensor_df.iloc[idx].values, dtype=torch.float32)\n",
    "        return image, sensors, label\n",
    "\n",
    "full_ds = SensorImageDataset(train_ds, sensors)\n",
    "loader = DataLoader(full_ds, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ee76b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model combining CNN features with sensor data\n",
    "import torch.nn as nn\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.fc_image = nn.Linear(32, 16)\n",
    "        self.fc_sensor = nn.Linear(3, 16)\n",
    "        self.classifier = nn.Linear(32, 10)\n",
    "    def forward(self, x_img, x_sensor):\n",
    "        x = self.cnn(x_img)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x_img_feat = self.fc_image(x)\n",
    "        x_sensor_feat = self.fc_sensor(x_sensor)\n",
    "        x = torch.cat([x_img_feat, x_sensor_feat], dim=1)\n",
    "        return self.classifier(x)\n",
    "model = SimpleModel()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eb87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for a few epochs\n",
    "for epoch in range(2):\n",
    "    for images, sensor_values, labels in loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images, sensor_values)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1} complete, loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b19e3",
   "metadata": {},
   "source": [
    "Training complete."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
